{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyod.models.knn import KNN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Reading#  Mote-ID      H      T  Label\n",
      "0            1        1  45.93  27.97      0\n",
      "1            2        1  45.90  27.95      0\n",
      "2            3        1  45.90  27.96      0\n",
      "3            4        1  45.93  27.95      0\n",
      "4            5        1  45.93  27.97      0\n",
      "...        ...      ...    ...    ...    ...\n",
      "4412      4413        1  42.62  27.04      0\n",
      "4413      4414        1  42.62  27.04      0\n",
      "4414      4415        1  42.62  27.05      0\n",
      "4415      4416        1  42.62  27.05      0\n",
      "4416      4417        1  42.62  27.05      0\n",
      "\n",
      "[4417 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"singlehop-indoor-moteid1-data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['H', 'T','Label']\n",
    "columns_train = ['H', 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "NormalData = df.loc[(df['Label'] == 0), columns]  # get Normal Data\n",
    "print(len(NormalData))\n",
    "\n",
    "AbnormalData = df.loc[(df['Label'] == 1), columns] # get AbNormal Data\n",
    "print(len(AbnormalData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Label'].values\n",
    "features = df[list(columns_train)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.35114330993888 0.0 0.0 0.0 0.0 \n",
      "\n",
      "For k: 2\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "98.66425175458457 0.9316239316239316 0.7904811123537167 0.01186046511627907 0.7870036101083032 \n",
      "\n",
      "For k: 3\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.32850350916912 0.9658119658119658 0.6831431172971272 0.026511627906976743 0.6569767441860465 \n",
      "\n",
      "For k: 4\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "96.53611048222776 1.0 0.646463246195923 0.03558139534883721 0.6046511627906976 \n",
      "\n",
      "For k: 5\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.72107765451663 1.0 0.6046049913972221 0.04395348837209302 0.5531914893617021 \n",
      "\n",
      "For k: 6\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.8795562599049 1.0 0.6121618771222364 0.04232558139534884 0.5625 \n",
      "\n",
      "For k: 7\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.24564183835183 1.0 0.5833732092398493 0.04883720930232558 0.527027027027027 \n",
      "\n",
      "For k: 8\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.20036223681232 1.0 0.5814551181548759 0.04930232558139535 0.5246636771300448 \n",
      "\n",
      "For k: 9\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.99660402988454 1.0 0.5730297972003092 0.0513953488372093 0.5142857142857142 \n",
      "\n",
      "For k: 10\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.56644781525922 1.0 0.5562725271726118 0.05581395348837209 0.4936708860759494 \n",
      "\n",
      "For k: 11\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.0645234321938 1.0 0.5758015104028115 0.05069767441860465 0.5176991150442478 \n",
      "\n",
      "For k: 12\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.90604482680553 1.0 0.5693895032091381 0.05232558139534884 0.5098039215686274 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,13):\n",
    "    clf = KNN(n_neighbors=k, method='median',  metric='manhattan')\n",
    "    clf.fit(features)\n",
    "    y_test_pred = clf.predict(features)\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "\n",
    "    results = confusion_matrix(labels, y_test_pred)\n",
    "    TN = results[0][0]\n",
    "    FP = results[0][1]\n",
    "    FN = results[1][0]\n",
    "    TP = results[1][1]\n",
    "\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "    TPR=TP/(TP+FN)\n",
    "    MCC=matthews_corrcoef(labels, y_test_pred)\n",
    "    FPR=FP/(FP+TN)\n",
    "    F1_Score=(2*TP)/((2*TP)+FP+FN)\n",
    "\n",
    "    print(f\"For k: {k}\")\n",
    "    print(f\"Accuracy, TPR, MCC, FPR, F1 Score\")\n",
    "    print(accuracy, TPR, MCC, FPR, F1_Score, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.35114330993888 0.0 0.0 0.0 0.0 \n",
      "\n",
      "For k: 2\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.32850350916912 0.9658119658119658 0.6831431172971272 0.026511627906976743 0.6569767441860465 \n",
      "\n",
      "For k: 3\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.72107765451663 1.0 0.6046049913972221 0.04395348837209302 0.5531914893617021 \n",
      "\n",
      "For k: 4\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.24564183835183 1.0 0.5833732092398493 0.04883720930232558 0.527027027027027 \n",
      "\n",
      "For k: 5\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.99660402988454 1.0 0.5730297972003092 0.0513953488372093 0.5142857142857142 \n",
      "\n",
      "For k: 6\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.0645234321938 1.0 0.5758015104028115 0.05069767441860465 0.5176991150442478 \n",
      "\n",
      "For k: 7\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.70228661987774 1.0 0.5614212308504305 0.05441860465116279 0.5 \n",
      "\n",
      "For k: 8\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.49852841294997 1.0 0.5537451768911694 0.056511627906976745 0.49056603773584906 \n",
      "\n",
      "For k: 9\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.47588861218021 1.0 0.5529095296815081 0.05674418604651163 0.4895397489539749 \n",
      "\n",
      "For k: 10\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "93.90989359293638 1.0 0.5330542985164716 0.06255813953488372 0.46520874751491054 \n",
      "\n",
      "For k: 11\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "93.70613538600861 1.0 0.5263579519235319 0.06465116279069767 0.45703125 \n",
      "\n",
      "For k: 12\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.06837219832465 1.0 0.5384213286565054 0.060930232558139535 0.4717741935483871 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,13):\n",
    "    clf = KNN(n_neighbors=k, method='largest',  metric='manhattan')\n",
    "    clf.fit(features)\n",
    "    y_test_pred = clf.predict(features)\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "\n",
    "    results = confusion_matrix(labels, y_test_pred)\n",
    "    TN = results[0][0]\n",
    "    FP = results[0][1]\n",
    "    FN = results[1][0]\n",
    "    TP = results[1][1]\n",
    "\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "    TPR=TP/(TP+FN)\n",
    "    MCC=matthews_corrcoef(labels, y_test_pred)\n",
    "    FPR=FP/(FP+TN)\n",
    "    F1_Score=(2*TP)/((2*TP)+FP+FN)\n",
    "\n",
    "    print(f\"For k: {k}\")\n",
    "    print(f\"Accuracy, TPR, MCC, FPR, F1 Score\")\n",
    "    print(accuracy, TPR, MCC, FPR, F1_Score, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k: 1\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.35114330993888 0.0 0.0 0.0 0.0 \n",
      "\n",
      "For k: 2\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "98.66425175458457 0.9316239316239316 0.7904811123537167 0.01186046511627907 0.7870036101083032 \n",
      "\n",
      "For k: 3\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.89449852841295 1.0 0.738304153622214 0.021627906976744184 0.7155963302752294 \n",
      "\n",
      "For k: 4\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "97.07946570070185 1.0 0.6792212183189171 0.03 0.6446280991735537 \n",
      "\n",
      "For k: 5\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "96.60402988453701 1.0 0.6503200152917017 0.03488372093023256 0.609375 \n",
      "\n",
      "For k: 6\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.99275526375368 1.0 0.6177200604559487 0.041162790697674416 0.5693430656934306 \n",
      "\n",
      "For k: 7\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.65315825220738 1.0 0.6014432855552089 0.044651162790697675 0.5492957746478874 \n",
      "\n",
      "For k: 8\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.26828163912158 1.0 0.5843386902736953 0.048604651162790696 0.5282167042889391 \n",
      "\n",
      "For k: 9\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.1098030337333 1.0 0.5776695198529956 0.05023255813953489 0.52 \n",
      "\n",
      "For k: 10\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "95.08716323296355 1.0 0.5767334749983558 0.050465116279069765 0.5188470066518847 \n",
      "\n",
      "For k: 11\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.90604482680553 1.0 0.5693895032091381 0.05232558139534884 0.5098039215686274 \n",
      "\n",
      "For k: 12\n",
      "Accuracy, TPR, MCC, FPR, F1 Score\n",
      "94.74756622141726 1.0 0.5631660446702442 0.053953488372093024 0.5021459227467812 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,13):\n",
    "    clf = KNN(n_neighbors=k, method='mean',  metric='manhattan')\n",
    "    clf.fit(features)\n",
    "    y_test_pred = clf.predict(features)\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "\n",
    "    results = confusion_matrix(labels, y_test_pred)\n",
    "    TN = results[0][0]\n",
    "    FP = results[0][1]\n",
    "    FN = results[1][0]\n",
    "    TP = results[1][1]\n",
    "\n",
    "    accuracy = accuracy_score(labels, y_test_pred) * 100\n",
    "    TPR=TP/(TP+FN)\n",
    "    MCC=matthews_corrcoef(labels, y_test_pred)\n",
    "    FPR=FP/(FP+TN)\n",
    "    F1_Score=(2*TP)/((2*TP)+FP+FN)\n",
    "\n",
    "    print(f\"For k: {k}\")\n",
    "    print(f\"Accuracy, TPR, MCC, FPR, F1 Score\")\n",
    "    print(accuracy, TPR, MCC, FPR, F1_Score, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
